{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.gridspec import GridSpec, GridSpecFromSubplotSpec\n",
    "import seaborn as sb\n",
    "import numpy as np\n",
    "import sklearn\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path= r\"C:\\Users\\subha\\Desktop\\AgriSage\\Crop_Recommendation.csv\"\n",
    "raw_data= pd.read_csv (file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Nitrogen', 'Phosphorus', 'Potassium', 'Temperature', 'Humidity',\n",
       "       'pH_Value', 'Rainfall'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features= raw_data.columns[:-1]\n",
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 'Crop'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.discriminant_analysis import StandardScaler\n",
    "from sklearn.preprocessing import QuantileTransformer\n",
    "\n",
    "\n",
    "def transform_data(df, target, num_features):\n",
    "    # Encoding target\n",
    "    lbl_encoder = LabelEncoder()\n",
    "    df[target+'_Encoded'] = lbl_encoder.fit_transform(df[target])\n",
    "    \n",
    "    # Assigning features and labels\n",
    "    x = df.drop([target, target+'_Encoded'], axis=1)\n",
    "    y = df[target+'_Encoded']\n",
    "    \n",
    "    # Splitting the dataset into train and test sets\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, stratify=y)\n",
    "    \n",
    "    # Accessing the encoded classes\n",
    "    encoded_classes = lbl_encoder.classes_\n",
    "    # Printing the mapping (index corresponds to encoded value, value is the original label)\n",
    "    for i, label in enumerate(encoded_classes):\n",
    "        print(f\"Encoded Value: {i}, Original Label: {label}\")    \n",
    "    \n",
    "    # Standardization and Encoding\n",
    "    # Define transformers for different column types\n",
    "    std_scaler = StandardScaler()\n",
    "    quantile_transformer = QuantileTransformer(output_distribution='normal', random_state=0)\n",
    "\n",
    "    # Combine transformers for specific columns\n",
    "    preprocessor = ColumnTransformer([\n",
    "        (\"num\", std_scaler, num_features),\n",
    "        (\"num_trns\", quantile_transformer, num_features)\n",
    "    ])\n",
    "     # Fit transformers on training data only\n",
    "    preprocessor.fit(x_train)\n",
    "\n",
    "    # Transform train and test data using fitted transformers\n",
    "    x_train_transformed = preprocessor.transform(x_train)\n",
    "    x_test_transformed = preprocessor.transform(x_test)\n",
    "    \n",
    "    return x_train_transformed, x_test_transformed, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoded Value: 0, Original Label: Apple\n",
      "Encoded Value: 1, Original Label: Banana\n",
      "Encoded Value: 2, Original Label: Blackgram\n",
      "Encoded Value: 3, Original Label: ChickPea\n",
      "Encoded Value: 4, Original Label: Coconut\n",
      "Encoded Value: 5, Original Label: Coffee\n",
      "Encoded Value: 6, Original Label: Cotton\n",
      "Encoded Value: 7, Original Label: Grapes\n",
      "Encoded Value: 8, Original Label: Jute\n",
      "Encoded Value: 9, Original Label: KidneyBeans\n",
      "Encoded Value: 10, Original Label: Lentil\n",
      "Encoded Value: 11, Original Label: Maize\n",
      "Encoded Value: 12, Original Label: Mango\n",
      "Encoded Value: 13, Original Label: MothBeans\n",
      "Encoded Value: 14, Original Label: MungBean\n",
      "Encoded Value: 15, Original Label: Muskmelon\n",
      "Encoded Value: 16, Original Label: Orange\n",
      "Encoded Value: 17, Original Label: Papaya\n",
      "Encoded Value: 18, Original Label: PigeonPeas\n",
      "Encoded Value: 19, Original Label: Pomegranate\n",
      "Encoded Value: 20, Original Label: Rice\n",
      "Encoded Value: 21, Original Label: Watermelon\n"
     ]
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = transform_data(raw_data, target, features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold, cross_validate\n",
    "\n",
    "\n",
    "def model_comparison(x, y, models):\n",
    "    names = []\n",
    "    scoring = ['accuracy']\n",
    "    \n",
    "    # Create a dataframe to store the different metric values for each algorithm\n",
    "    df_results = pd.DataFrame(columns=['Algorithm', 'Acc Mean', 'Acc STD'])\n",
    "    results_acc = [] # List of accuracy scores for each fold of each algorithm\n",
    "    \n",
    "    for name, model in models:\n",
    "        names.append(name)\n",
    "        kfold = StratifiedKFold(n_splits=10, shuffle=True, random_state=101)\n",
    "        result = cross_validate(model, x, y, cv=kfold, scoring=scoring)\n",
    "        # Mean and standard deviation of Accuracy scores for the algorithm\n",
    "        acc_mean = result['test_accuracy'].mean()\n",
    "        acc_std = result['test_accuracy'].std()\n",
    "        \n",
    "        # Create the row of the results\n",
    "        df_result_row = {'Algorithm': name, 'Acc Mean': acc_mean, 'Acc STD': acc_std}\n",
    "        # Add the row to the results data frame\n",
    "        df_results = pd.concat([df_results, pd.DataFrame([df_result_row])], ignore_index=True)\n",
    "        \n",
    "        results_acc.append(result['test_accuracy'])\n",
    "        \n",
    "    df_results = df_results.set_index('Algorithm')\n",
    "    pd.set_option('display.float_format', lambda x: '%.3f' % x)\n",
    "    # Display the mean and standard deviation of all metrics for all algorithms\n",
    "    print(df_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier, GradientBoostingClassifier, RandomForestClassifier\n",
    "\n",
    "\n",
    "ens_models = []\n",
    "ens_models.append(('RFC', RandomForestClassifier()))\n",
    "ens_models.append(('ABC', AdaBoostClassifier()))\n",
    "ens_models.append(('GBC', GradientBoostingClassifier()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\subha\\AppData\\Local\\Temp\\ipykernel_19436\\3169022010.py:23: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_results = pd.concat([df_results, pd.DataFrame([df_result_row])], ignore_index=True)\n",
      "c:\\Users\\subha\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\subha\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\subha\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\subha\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\subha\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\subha\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\subha\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\subha\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\subha\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\subha\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           Acc Mean  Acc STD\n",
      "Algorithm                   \n",
      "RFC           0.995    0.005\n",
      "ABC           0.177    0.014\n",
      "GBC           0.990    0.007\n"
     ]
    }
   ],
   "source": [
    "model_comparison(x_train, y_train, ens_models)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ensemble model vs non linear models.\n",
    "DecisionTreeClassifier()\n",
    "KNeighborsClassifier()\n",
    "GaussianNB()\n",
    "XGBClassifier()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
