{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.gridspec import GridSpec, GridSpecFromSubplotSpec\n",
    "import seaborn as sb\n",
    "import numpy as np\n",
    "import sklearn\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "# Suppress specific warning\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "\n",
    "# Suppress all warnings\n",
    "warnings.filterwarnings(\"ignore\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path= r\"C:\\Users\\subha\\Desktop\\AgriSage\\Crop_Recommendation.csv\"\n",
    "raw_data= pd.read_csv (file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Nitrogen', 'Phosphorus', 'Potassium', 'Temperature', 'Humidity',\n",
       "       'pH_Value', 'Rainfall'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features= raw_data.columns[:-1]\n",
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 'Crop'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.discriminant_analysis import StandardScaler\n",
    "from sklearn.preprocessing import QuantileTransformer\n",
    "\n",
    "\n",
    "def transform_data(df, target, num_features):\n",
    "    # Ensure num_features is a list\n",
    "    if isinstance(num_features, pd.Index):\n",
    "        num_features = num_features.tolist()\n",
    "\n",
    "    # Encoding target\n",
    "    lbl_encoder = LabelEncoder()\n",
    "    df[target+'_Encoded'] = lbl_encoder.fit_transform(df[target])\n",
    "    \n",
    "    # Assigning features and labels\n",
    "    x = df.drop([target, target+'_Encoded'], axis=1)\n",
    "    y = df[target+'_Encoded']\n",
    "    \n",
    "    # Splitting the dataset into train and test sets\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, stratify=y, random_state=101)\n",
    "    \n",
    "    # Accessing the encoded classes\n",
    "    encoded_classes = lbl_encoder.classes_\n",
    "    # Printing the mapping (index corresponds to encoded value, value is the original label)\n",
    "    for i, label in enumerate(encoded_classes):\n",
    "        print(f\"Encoded Value: {i}, Original Label: {label}\")    \n",
    "    \n",
    "    # Standardization and Encoding\n",
    "    # Define transformers for different column types\n",
    "    std_scaler = StandardScaler()\n",
    "    quantile_transformer = QuantileTransformer(output_distribution='normal', random_state=0)\n",
    "\n",
    "    # Combine transformers for specific columns\n",
    "    preprocessor = ColumnTransformer([\n",
    "        (\"num\", std_scaler, num_features),\n",
    "        (\"num_trns\", quantile_transformer, num_features)\n",
    "    ])\n",
    "     # Fit transformers on training data only\n",
    "    preprocessor.fit(x_train)\n",
    "\n",
    "    # Transform train and test data using fitted transformers\n",
    "    x_train_transformed = preprocessor.transform(x_train)\n",
    "    x_test_transformed = preprocessor.transform(x_test)\n",
    "\n",
    "    # Calculate statistics for numerical features before and after transformation\n",
    "    stats = {}\n",
    "    for i, feature in enumerate(num_features):\n",
    "        stats[feature] = {\n",
    "            'mean_before': x_train[feature].mean(),\n",
    "            'std_before': x_train[feature].std(),\n",
    "            'mean_after': x_train_transformed[:, i].mean(),\n",
    "            'std_after': x_train_transformed[:, i].std()\n",
    "        }\n",
    "    \n",
    "    return x_train_transformed, x_test_transformed, y_train, y_test, stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoded Value: 0, Original Label: Apple\n",
      "Encoded Value: 1, Original Label: Banana\n",
      "Encoded Value: 2, Original Label: Blackgram\n",
      "Encoded Value: 3, Original Label: ChickPea\n",
      "Encoded Value: 4, Original Label: Coconut\n",
      "Encoded Value: 5, Original Label: Coffee\n",
      "Encoded Value: 6, Original Label: Cotton\n",
      "Encoded Value: 7, Original Label: Grapes\n",
      "Encoded Value: 8, Original Label: Jute\n",
      "Encoded Value: 9, Original Label: KidneyBeans\n",
      "Encoded Value: 10, Original Label: Lentil\n",
      "Encoded Value: 11, Original Label: Maize\n",
      "Encoded Value: 12, Original Label: Mango\n",
      "Encoded Value: 13, Original Label: MothBeans\n",
      "Encoded Value: 14, Original Label: MungBean\n",
      "Encoded Value: 15, Original Label: Muskmelon\n",
      "Encoded Value: 16, Original Label: Orange\n",
      "Encoded Value: 17, Original Label: Papaya\n",
      "Encoded Value: 18, Original Label: PigeonPeas\n",
      "Encoded Value: 19, Original Label: Pomegranate\n",
      "Encoded Value: 20, Original Label: Rice\n",
      "Encoded Value: 21, Original Label: Watermelon\n"
     ]
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test, stats = transform_data(raw_data, target, features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold, cross_validate\n",
    "\n",
    "\n",
    "def model_comparison(x, y, models, stats):\n",
    "    names = []\n",
    "    scoring = ['accuracy']\n",
    "    \n",
    "    # Create a dataframe to store the different metric values for each algorithm\n",
    "    df_results = pd.DataFrame(columns=['Algorithm', 'Acc Mean', 'Acc STD'])\n",
    "    results_acc = [] # List of accuracy scores for each fold of each algorithm\n",
    "    \n",
    "    for name, model in models:\n",
    "        names.append(name)\n",
    "        kfold = StratifiedKFold(n_splits=10, shuffle=True, random_state=101)\n",
    "        result = cross_validate(model, x, y, cv=kfold, scoring=scoring)\n",
    "        # Mean and standard deviation of Accuracy scores for the algorithm\n",
    "        acc_mean = result['test_accuracy'].mean()\n",
    "        acc_std = result['test_accuracy'].std()\n",
    "        \n",
    "        # Create the row of the results\n",
    "        df_result_row = {'Algorithm': name, 'Acc Mean': acc_mean, 'Acc STD': acc_std}\n",
    "        # Add the row to the results data frame\n",
    "        df_results = pd.concat([df_results, pd.DataFrame([df_result_row])], ignore_index=True)\n",
    "        \n",
    "        results_acc.append(result['test_accuracy'])\n",
    "\n",
    "    # Add the means and standard deviations of the encoded variables to the results dataframe\n",
    "    for feature, stat in stats.items():\n",
    "        df_results[f'{feature} Mean Before'] = stat['mean_before']\n",
    "        df_results[f'{feature} STD Before'] = stat['std_before']\n",
    "        df_results[f'{feature} Mean After'] = stat['mean_after']\n",
    "        df_results[f'{feature} STD After'] = stat['std_after']\n",
    "        \n",
    "    df_results = df_results.set_index('Algorithm')\n",
    "    pd.set_option('display.float_format', lambda x: '%.3f' % x)\n",
    "    # Display the mean and standard deviation of all metrics for all algorithms\n",
    "    print(df_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier, GradientBoostingClassifier, RandomForestClassifier\n",
    "\n",
    "\n",
    "ens_models = []\n",
    "ens_models.append(('RFC', RandomForestClassifier()))\n",
    "ens_models.append(('ABC', AdaBoostClassifier()))\n",
    "ens_models.append(('GBC', GradientBoostingClassifier()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           Acc Mean  Acc STD  Nitrogen Mean Before  Nitrogen STD Before  \\\n",
      "Algorithm                                                                 \n",
      "RFC           0.993    0.005                50.464               36.970   \n",
      "ABC           0.177    0.014                50.464               36.970   \n",
      "GBC           0.988    0.009                50.464               36.970   \n",
      "\n",
      "           Nitrogen Mean After  Nitrogen STD After  Phosphorus Mean Before  \\\n",
      "Algorithm                                                                    \n",
      "RFC                      0.000               1.000                  53.398   \n",
      "ABC                      0.000               1.000                  53.398   \n",
      "GBC                      0.000               1.000                  53.398   \n",
      "\n",
      "           Phosphorus STD Before  Phosphorus Mean After  Phosphorus STD After  \\\n",
      "Algorithm                                                                       \n",
      "RFC                       33.133                 -0.000                 1.000   \n",
      "ABC                       33.133                 -0.000                 1.000   \n",
      "GBC                       33.133                 -0.000                 1.000   \n",
      "\n",
      "           ...  Humidity Mean After  Humidity STD After  pH_Value Mean Before  \\\n",
      "Algorithm  ...                                                                  \n",
      "RFC        ...               -0.000               1.000                 6.473   \n",
      "ABC        ...               -0.000               1.000                 6.473   \n",
      "GBC        ...               -0.000               1.000                 6.473   \n",
      "\n",
      "           pH_Value STD Before  pH_Value Mean After  pH_Value STD After  \\\n",
      "Algorithm                                                                 \n",
      "RFC                      0.772                0.000               1.000   \n",
      "ABC                      0.772                0.000               1.000   \n",
      "GBC                      0.772                0.000               1.000   \n",
      "\n",
      "           Rainfall Mean Before  Rainfall STD Before  Rainfall Mean After  \\\n",
      "Algorithm                                                                   \n",
      "RFC                     103.651               55.224               -0.000   \n",
      "ABC                     103.651               55.224               -0.000   \n",
      "GBC                     103.651               55.224               -0.000   \n",
      "\n",
      "           Rainfall STD After  \n",
      "Algorithm                      \n",
      "RFC                     1.000  \n",
      "ABC                     1.000  \n",
      "GBC                     1.000  \n",
      "\n",
      "[3 rows x 30 columns]\n"
     ]
    }
   ],
   "source": [
    "model_comparison(x_train, y_train, ens_models,stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ensemble model vs non linear models.\n",
    "DecisionTreeClassifier()\n",
    "KNeighborsClassifier()\n",
    "GaussianNB()\n",
    "XGBClassifier()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
