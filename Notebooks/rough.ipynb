{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def z_score_normalization(data, features):\n",
    "    for i in range(len(features)):\n",
    "        mean_value = data[features[i]].mean()\n",
    "        median_value = data[features[i]].median()\n",
    "        std_dev= data [features[i]].std()\n",
    "        z_scores = (data - mean_value) / std_dev\n",
    "        return z_scores\n",
    "    normalized_data = z_score_normalization(raw_data, features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dist_plot(data, feature_list):\n",
    "    n_cols= 2 \n",
    "    n_rows = int(np.ceil(len(feature_list)/n_cols)) \n",
    "    # Creating figure\n",
    "    fig = plt.figure(figsize=(16, 4*n_rows))\n",
    "    outer = GridSpec(n_rows, n_cols, wspace=0.2, hspace=0.3)\n",
    "\n",
    "    for i in range(len(feature_list)):\n",
    "        inner = GridSpecFromSubplotSpec(2, 1, subplot_spec=outer[i], \n",
    "                                                 wspace=0.1, hspace=0.1, height_ratios=(0.15, 0.85))\n",
    "        ax_box= plt.Subplot(fig, inner[0])\n",
    "        sb.boxplot(data=data, x=feature_list[i], color='lightblue', ax=ax_box)\n",
    "        ax_box.set_xlabel('')\n",
    "        fig.add_subplot(ax_box)\n",
    "\n",
    "        mean_value = data[feature_list[i]].mean()\n",
    "        median_value = data[feature_list[i]].median()\n",
    "        ax_hist = plt.Subplot(fig, inner[1])\n",
    "        sb.histplot(data=data, x=feature_list[i], kde=True, ax=ax_hist)\n",
    "        ax_hist.axvline(mean_value, color='green', linestyle='dotted', linewidth=2, label='Mean')\n",
    "        ax_hist.axvline(median_value, color='purple', linestyle='dotted', linewidth=2, label='Median')\n",
    "        ax_hist.legend(loc='lower right', fontsize=10)\n",
    "\n",
    "        # Calculate skewness and kurtosis\n",
    "        skewness = data[feature_list[i]].skew()\n",
    "        kurt = data[feature_list[i]].kurt()\n",
    "        if skewness < 0:\n",
    "            x=0.25\n",
    "        else:\n",
    "            x=0.95\n",
    "        # Add skewness and kurtosis as text on the histogram plot\n",
    "        ax_hist.text(x, 0.85, f\"Skewness: {skewness:.2f}\\nKurtosis: {kurt:.2f}\", \n",
    "                         transform=ax_hist.transAxes, verticalalignment='top', horizontalalignment='right',\n",
    "                         bbox=dict(facecolor='white', edgecolor='gray', boxstyle='round,pad=0.5'),\n",
    "                    fontsize=10)\n",
    "        fig.add_subplot(ax_hist)\n",
    "    plt.tight_layout()\n",
    "    plt.show(block=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist_plot(normalized_data, features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_transformation(data):\n",
    "    return np.log(data)\n",
    "data = raw_data\n",
    "transformed_data = log_transformation(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, QuantileTransformer, OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "\n",
    "def transform_data(df, target, num_features):\n",
    "    # Ensure num_features is a list\n",
    "    if isinstance(num_features, pd.Index):\n",
    "        num_features = num_features.tolist()\n",
    "        \n",
    "    # Encoding target\n",
    "    onehot_encoder = OneHotEncoder(sparse_output=False)\n",
    "    target_encoded = onehot_encoder.fit_transform(df[[target]])\n",
    "    \n",
    "    # Creating a DataFrame with encoded target columns\n",
    "    target_encoded_df = pd.DataFrame(target_encoded, columns=[f\"{target}_{cat}\" for cat in onehot_encoder.categories_[0]])\n",
    "    \n",
    "    # Concatenate the original DataFrame with the new one-hot encoded target columns\n",
    "    df = pd.concat([df.drop(target, axis=1), target_encoded_df], axis=1)\n",
    "    \n",
    "    # Assigning features and labels\n",
    "    x = df.drop(target_encoded_df.columns, axis=1)\n",
    "    y = target_encoded_df\n",
    "    \n",
    "    # Splitting the dataset into train and test sets\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, stratify=y, random_state=101)\n",
    "    \n",
    "    # Standardization and Encoding\n",
    "    # Define transformers for different column types\n",
    "    std_scaler = StandardScaler()\n",
    "    quantile_transformer = QuantileTransformer(output_distribution='normal', random_state=0)\n",
    "\n",
    "    # Combine transformers for specific columns\n",
    "    preprocessor = ColumnTransformer([\n",
    "        (\"num\", std_scaler, num_features),\n",
    "        (\"num_trns\", quantile_transformer, num_features)\n",
    "    ])\n",
    "    \n",
    "    # Fit transformers on training data only\n",
    "    preprocessor.fit(x_train)\n",
    "\n",
    "    # Transform train and test data using fitted transformers\n",
    "    x_train_transformed = preprocessor.transform(x_train)\n",
    "    x_test_transformed = preprocessor.transform(x_test)\n",
    "    \n",
    "    return x_train_transformed, x_test_transformed, y_train, y_test"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
